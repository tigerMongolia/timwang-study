### 一. HashMap（JDK-1.8）

#### 0. 哈希表



#### 1. 简介

HashMap采用key/value存储结构，每个key对应唯一的value，查询和修改的速度都很快，能达到O(1)的平均时间复杂度。它是非线程安全的，且不保证元素存储的顺序；

#### 2. 继承体系

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfueavdpswj30bs06eq2u.jpg" style="zoom:100%;float:left" />

HashMap实现了Cloneable，可以被克隆。

HashMap实现了Serializable，可以被序列化。

HashMap继承自AbstractMap，实现了Map接口，具有Map的所有功能。

#### 3.HashMap存储结构

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfuecwf0y0j30r20hxgmm.jpg" alt="image-20200205095809050" style="zoom:50%;float:left" />

##### 3.1 结构说明

在Java中，HashMap的实现采用了（数组 + 链表 + 红黑树）的复杂结构，数组的一个元素又称作桶。

1. 在添加元素时，会根据hash值算出元素在数组中的位置，如果该位置没有元素，则直接把元素放置在此处，如果该位置有元素了，则把元素以链表的形式放置在链表的尾部。

2. 当一个链表的元素个数达到一定的数量（且数组的长度达到一定的长度）后，则把链表转化为红黑树，从而提高效率。

3. 数组的查询效率为O(1)，链表的查询效率是O(k)，红黑树的查询效率是O(log k)，k为桶中的元素个数，所以当元素数量非常多的时候，转化为红黑树能极大地提高效率。

##### 3.2 为什么会转换成红黑树？

1. 这个是在java8中做的优化，目的是当hash碰撞严重的时候，链表过长，通过树可以提升查找效率（链表是n ,树是logn），之所以用红黑树，是因为红黑树是平衡树，平衡树的特点是叶子节点的高度差不会大于1，这样可以避免树在极端情况下退化成链表，导致优化了等于白给。

##### 3.3 为什么不全部链表转红黑树

1. 第一个是链表的结构比红黑树简单，构造红黑树要比构造链表复杂，所以在链表的节点不多的情况下，从整体的性能看来，
   数组+链表+红黑树的结构不一定比数组+链表的结构性能高。
2. 第二个是HashMap频繁的resize（扩容），扩容的时候需要重新计算节点的索引位置，也就是会将红黑树进行拆分和重组其实
   这是很复杂的，这里涉及到红黑树的着色和旋转，这又是一个比链表结构耗时的操作，所以为链表树化设置一个阀值是非常有必要的。

#### 4. 源码解析

##### 4.1 HashMap注释

1. 允许NULL值，NULL键
2. 不要轻易改变负载因子，负载因子过高会导致链表过长，查找键值对时间复杂度就会增高，负载因子过低会导致hash桶的 数量过多，空间复杂度会增高
3. Hash表每次会扩容长度为以前的2倍
4. HashMap是多线程不安全的，我在JDK1.7进行多线程put操作，之后遍历，直接死循环，CPU飙到100%，在JDK 1.8中进行多线程操作会出现节点和value值丢失，为什么JDK1.7与JDK1.8多线程操作会出现很大不同，是因为JDK 1.8的作者对resize方法进行了优化不会产生链表闭环。这也是本章的重点之一，具体的细节大家可以去查阅资料。这里我就不解释太多了
5. 尽量设置HashMap的初始容量，尤其在数据量大的时候，防止多次resize

##### 4.2 类常量

```Java
//默认hash桶初始长度16
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; 

//hash表最大容量2的30次幂
static final int MAXIMUM_CAPACITY = 1 << 30;

//默认负载因子 0.75
static final float DEFAULT_LOAD_FACTOR = 0.75f;

//链表的数量大于等于8个并且桶的数量大于等于64时链表树化 
static final int TREEIFY_THRESHOLD = 8;

//hash表某个节点链表的数量小于等于6时树拆分
static final int UNTREEIFY_THRESHOLD = 6;

//树化时最小桶的数量
static final int MIN_TREEIFY_CAPACITY = 64;
```

##### 4.3 实例变量

```java
//hash桶
transient Node<K,V>[] table;                         

//键值对的数量
transient int size;

//HashMap结构修改的次数
transient int modCount;

//扩容的阀值，当键值对的数量超过这个阀值会产生扩容
int threshold;

//负载因子
final float loadFactor;
```

#### 5. 构造方法

##### 5.1 构造方法

HashMap 的四种构造函数

###### 5.1.1 HashMap()

```java
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}
```

可以看到，无参构造函数只是把 DEFAULT_LOAD_FACTOR 的值（默认 0.75）赋值给 loadFactor，loadFactor 是给 HashTable 用的，所以可以理解为啥正事都没干。

###### 5.1.2 HashMap(int initialCapacity)

```java
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}
```

一般我们实际使用过程中都是用的这个，在新建一个 HashMap 的时候先预估存储的元素的个数，假设个数为 n ，然后用 n 除以 0.75 ，假设算出的值是 m ，initialCapacity 取不小于 m 的 2 的幂次方对应的值。

举个例子：我现假设要往 HashMap 中存入 17 个值，17 / 0.75 = 22.67 。取不小于 22.67 的最近的 2 的幂次方，最终 initialCapacity 取 32（2的5次方） 。即 new HashMap(32) 。

为什么 initialCapacity 要取 2 的幂次方呢？之后我们讲 put 方法的时候会讲到。

如果我脑残，非要 new HashMap(17) ，会发生什么呢？请看另外一个构造方法

###### 5.1.3 HashMap(int initialCapacity, float loadFactor) 

```java
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);
}
```

接上一个，此时，传入的 initialCapacity 是 17，loadFactor 是 0.75 。

第 2~9 行代码都是判断 initialCapacity 的合法性，是否小于 0 ，是否大于最大数组长度等等。

第 11 行代码才是重点，我们来看看 5.2 tableSizeFor 方法：

看注释，power of two 是二次方的意思。翻译一下就是，根据传进来的数返回一个合适的二次方的结果。 最终的结果就是传入 17，算出来的返回值是 32 ，最后 threshold 等于 32 。 此时 threshold 是临时保存初始化容量 initialCapacity 的值，在后面会有用到。

##### 5.2 阈值tableSizeFor初始化

我们最常使用的是无参构造，在这个构造方法里面仅仅设置了加载因子为默认值，其他两个参数会在resize方法里面进行初始化，在这里知道这个结论就可以了，下面会在源码里面进行分析； 另外一个带有两个参数的构造方法，里面对初始容量和阈值进行了初始化，对阈值的初始化方法为 tableSizeFor(int cap)，以10为例子进行分析

```java
 /**
  * 找到大于或等于 cap 的最小2的幂
  * 看注释，power of two 是二次方的意思。翻译一下就是，根据传进来的数返回一个合适的二次方的结果。 最终的结果就是传入 17，算出来的返回值是 32 ，最后 threshold 等于 32 。 此时 threshold 是临时保存初始化容量 initialCapacity 的值，在后面会有用到。
  */
static final int tableSizeFor(int cap) {                                                                      
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfuicr9mvcj30hj0jt3zp.jpg" alt="image-20200205095809050" style="zoom:50%;float:left" />

需要注意一下的是，第一步  int n = cap - 1; 这个操作，执行这个操作的主要原因是为了防止在cap已经是2的n次幂的情况下，经过运算后得到的结果是cap的二倍的结果，例如如果n为l6，经过一系列运算之后，得到的结果是0001 1111，此时最后一步n+1 执行之后，就会返回32，有兴趣的可以自己进行尝试；

##### 5.3 负载因子loadFactor取值

**我们应该很容易理解负载因子应该在 0.5~1.0 之间。**

- 如果小于 0.5，假设取 0.3 。初始化数组长度 16，threshold = 16*0.3 = 4.8 ，也就是数组长度大于 5 的时候进行扩容，扩容到 32 ；以此类推，数组长度 10 的时候，扩容到 64 。越往后，未使用的空间会越来越大，纯属浪费。

- 如果大于 1，假设取 1.5 。初始化数组长度 16，threshold = 16*1.5 = 24 。大家有没有发现一个问题，一个长度为 16 的数组要存储 24 条数据。那形成链表的几率就是百分之百了。会严重影响到查询的效率。

那为什么在 0.5~1.0 之间选择了 0.75 呢？0.6 行不行，0.8 行不行？

看看源码注释里面的一段话：

```Java
* <p>As a general rule, the default load factor (.75) offers a good
* tradeoff between time and space costs.  Higher values decrease the
* space overhead but increase the lookup cost (reflected in most of
* the operations of the <tt>HashMap</tt> class, including
* <tt>get</tt> and <tt>put</tt>).  The expected number of entries in
* the map and its load factor should be taken into account when
* setting its initial capacity, so as to minimize the number of
* rehash operations.  If the initial capacity is greater than the
* maximum number of entries divided by the load factor, no rehash
* operations will ever occur.
```

翻译一下，默认的负载因子 0.75 在时间和空间消耗上提供了一个平衡。较高的值会降低空间使用但是会增加查找消耗（会影响 put 和 get 方法）。map 期望的 entries 数量和负载因子在初始化的时候就要考虑到，这样可以降低 rehash 的次数。如果初始化的数组长度大于 map 存储数据的最大值除以负载因子，将不会有 rehash 发生。

其实官方的说法跟我上面实际使用中的取值方法一样，0.75 是官方认为最优的平衡时间和空间的值。至于 0.75 是怎么推算出来的，这是个数学问题。有兴趣的同学可以自行研究。

#### 6.put方法

##### 6.1 put()方法图示

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfuij80myaj311v0u041m.jpg" alt="image-20200205095809050" style="zoom:50%;float:left" />

##### 6.2 hash 扰动函数

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

上面代码里的key.hashCode()方法调用的是key键类型自带的哈希方法，返回整型散列值。理论上散列值是一个int类型，如果直接拿散列值作为下标访问HashMap主数组的话，考虑到2进制32位带符号的整型范围从-2147483648到2147483648，前后加起来大概40亿的映射空间。只要哈希方法映射地比较均匀松散，一般应用是很难出现碰撞的。

但问题是一个40亿长度的数组，内存是放不下的。各位想，HashMap的初始容量大小才16！所以这个散列值并不能直接拿来用，用之前还要先做对数组的长度取模运算，得到的余数再拿来访问数组下标。

jdk源码中的模运算是在indexFor()方法中完成的，indexFor()方法的代码很简单，就是把散列值和数组长度做一个“与”操作：

```java
static int indexFor(int h, int length){
    return h & (length - 1);
}
....
bucketIndex = indexFor(hash, table.length);
```

这里顺便讲一下为什么HashMap的数组长度要取2的整次幂。因为这样（数组长度-1）正好相当于一个“低位掩码”。“与操作”的结果就是散列值的高位全部归零，只保留低位值，用来做数组的下标。以初始长度16为例：16-1=15,2进制表示是 00000000 00000000 00001111。和某散列值做“与”操作的结果如下：

```hash
       10100101 11000100 00100101  //某散列值)
&      00000000 00000000 00001111
       00000000 00000000 00000101  //高位全部归零，只保留末四位
```

这时问题就来了，就算我们的散列值分布再松散，要是只取最后几位的话，碰撞会非常严重。更要命的是，如果散列本身做的不好，分布上成等差数列的漏洞，恰好使最后几个低位呈现规律性重复，这会无比蛋疼。
这时候“扰动方法”的价值就体现出来了，请看下图：

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfujbl6bcjj31hc0u077m.jpg" alt="image-20200205095809050" style="zoom:50%;float:left" />

右移16位，刚好是32位的一半，自己的高半区和低半区做异或（如果a、b两个值不相同，则异或结果为1。如果a、b两个值相同，异或结果为0），就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。
而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留了下来

##### 6.3  jdk 1.7和1.8的扰动函数

- Java7中的扰动做了四次，而到了Java8，觉得做一次就够了，多了边际效用也不大，这就是所谓的为了效率考虑就改成了1次扰动，相比较而言减少了过多的位运算，是一种折中的设计。

- 而且java8引入了红黑树，也可以增加散列的效率